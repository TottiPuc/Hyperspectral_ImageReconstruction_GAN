{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_data",
      "provenance": [],
      "authorship_tag": "ABX9TyOvRPsUvDx3Cjy/hdni93eO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhzU-gdSznO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "\n",
        "\n",
        "def Input_image(image):\n",
        "    images = loadmat(image).get('rad')\n",
        "    return images[0:500:2, 0:500:2, 0:3]\n",
        "\n",
        "\n",
        "def Oput_image(image):\n",
        "    images = loadmat(image).get('rad')\n",
        "    return images[:, :,0 :12]\n",
        "\n",
        "\n",
        "def load_sambles(data):\n",
        "    data = data[['inimg']]\n",
        "    inimg_name = list(data.iloc[:, 0])\n",
        "    samples = []\n",
        "    for samp in inimg_name:\n",
        "        samples.append(samp)\n",
        "    return samples\n",
        "\n",
        "def conv_array(samples, lenData, PATH, IMG_WIDTH, IMG_HEIGHT, L_imput, L_bands, shuffle=True):\n",
        "\n",
        "    X = np.empty((lenData, IMG_WIDTH, IMG_HEIGHT, L_imput )) \n",
        "    y = np.empty((lenData, 2 * IMG_WIDTH, 2 * IMG_HEIGHT, L_bands))\n",
        "    \n",
        "    for i, file_name in enumerate(samples):\n",
        "        # Store sample\n",
        "        X[i,] = Input_image(PATH + file_name)\n",
        "        # Store class\n",
        "        y[i,] = Oput_image(PATH  + file_name)\n",
        "    \n",
        "    return X,y\n",
        "\n",
        "def Build_data_set(IMG_WIDTH=250, IMG_HEIGHT=250, L_bands=31, L_imput=12, BATCH_SIZE=4, PATH=None):\n",
        "    # Random split\n",
        "    #data_dir_list = os.listdir(PATH)\n",
        "    data_dir_list = [f for f in os.listdir(PATH) if os.path.isfile(os.path.join(PATH, f))]\n",
        "    N = len(data_dir_list)\n",
        "    train_df = pd.DataFrame(columns=['inimg'])\n",
        "    test_df = pd.DataFrame(columns=['inimg'])\n",
        "    randurls = np.copy(data_dir_list)\n",
        "    train_n = round(N * 0.80)\n",
        "    np.random.shuffle(randurls)\n",
        "    tr_urls = randurls[:train_n]\n",
        "    ts_urls = randurls[train_n:N]\n",
        "    for i in tr_urls:\n",
        "        train_df = train_df.append({'inimg': i}, ignore_index=True)\n",
        "    for i in ts_urls:\n",
        "        test_df = test_df.append({'inimg': i}, ignore_index=True)\n",
        "        \n",
        "    partition_Train = load_sambles(train_df)\n",
        "    partition_Test = load_sambles(test_df)  \n",
        "    \n",
        "    params = {'IMG_WIDTH': IMG_WIDTH,\n",
        "          'IMG_HEIGHT': IMG_WIDTH,\n",
        "          'L_bands':L_bands,\n",
        "          'L_imput':L_imput,\n",
        "          'PATH': PATH,\n",
        "          'shuffle': True}\n",
        "    \n",
        "    train_data = conv_array(partition_Train, len(partition_Train), **params)\n",
        "    test_data = conv_array(partition_Test, len(partition_Test), **params)\n",
        "    \n",
        "    return train_data, test_data"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}